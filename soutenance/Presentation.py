import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from os import listdir
#python -m spacy download fr_core_news_lg
import spacy
#pip install time
#pip install warnings
import time
import warnings 
import platform

if platform.system() == "Darwin":  # macOS
    key_path = "/Users/lheyerda/Documents/GitHub/juil23_cds_supply_chain"
else:
    key_path = ".." 

# cache

@st.cache_data
def load_df():
    df = pd.read_csv(f"{key_path}/data/avis/general_df.csv", index_col=0)
    return df

@st.cache_data
def load_clean_df():
    df_cleaned = pd.read_csv(f"{key_path}/data/avis/df_cleaned.csv", index_col=0)
    return df_cleaned

@st.cache_data
def load_nlp():
    nlp = spacy.load("fr_core_news_lg")
    return nlp

@st.cache_data
def load_entreprises():
    ent = pd.read_csv(f"{key_path}/data/liste_entreprises_banque.csv", index_col=0)
    return ent

entreprises = load_entreprises()
df = load_df()
#df=df.iloc[:,1:]

df_cleaned = load_clean_df()
#tab=pd.read_csv(f"{key_path}/soutenance/describe_avis.csv")

nlp = load_nlp()

st.title("Projet d'analse des avis et verbatim")
st.sidebar.title("Sommaire")



pages=["I.	Introduction et objectif du projet", "II.	Pr√©parations des donn√©es ", "III.	Analyses descriptives des donn√©es", "IV.	Mod√©lisations I", "V.	Mod√©lisations II","VI.	Pr√©diction"]
page=st.sidebar.radio("Aller vers", pages)
st.sidebar.write("### √©quipe:")
st.sidebar.write("[L√©onard Heyerdahl](https://www.linkedin.com/in/leonardo-heyerdahl/)")
st.sidebar.write("Alexis Garatti")
st.sidebar.write("Huazhen Hou")
st.sidebar.write("Alexandre PRZYBYLSKI")



# PAGE 1 
if page == pages[0] : 
    st.write("### Introduction et objectif")
    st.write("Faire des mod√©lisations √† partir des avis et verbatim √† partir du site 'fr.trustpilot.com/categories/bank' afin d'analyser les verbatim et le lien entre les notations et les verbatim")
    st.write("- Pr√©dire la satisfaction d'un client : probl√®me de r√©gression et Entra√Ænement supervis√© possible.")
    st.write("- Identifier les points cl√©s des avis : localisation, nom d'entreprise... ")
    st.write("- Extraire les propos du commentaire et trouver les mots importants : probl√®me de livraison, article d√©fectueux... avec l'approche non supervis√©e avec CamemBert")
    st.write("- Trouver une r√©ponse rapide adapt√©e pour r√©pondre au commentaire, par exemple sur les reviews Google")


    st.write('### Aper√ßu des banques list√©es sur Trust Pilot (scrap)')
    st.write(entreprises)

    st.write("### Aper√ßu de la base de donn√©es des avis scrapp√©s")
    st.write(f"Nombre d'avis scrapp√©s: **{len(df)}**")
    st.dataframe(df)
    #st.dataframe(df.etoiles.describe())

    if st.checkbox("Afficher les NA") :
        st.dataframe(df.isna().sum())



if page == pages[1] : 
    st.write("### Pr√©parations des donn√©es")
    st.write("""
- **Retrait des avis li√©s √† une banque suspect√©e d'utiliser des bots**:
  - Environ 60 000 avis, majorit√© de 5 √©toiles.
- **Nettoyage des donn√©es**:
  - Retrait des na et des entr√©es de type incoh√©rent (str l√† ou donn√©es num√©riques attendues)
  - Conversion des dates au format datetime
- **Renforcement du dataframe**:
  - Ajout d'une colone contenant la longueur de l'avis en charact√®res
  - Ajout d'une colone du score de sentiment (probabilit√© x label postif (1) ou n√©gatif (-1)) inf√©r√© par CAMEMBERT
  - Concat√©nation du *titre de l'avis* et de *l'avis*, pour regrouper les donn√©es textuelles existantes
""")
    st.write("### Aper√ßu de la base de donn√©es nettoy√©e")

    st.dataframe(df_cleaned.head())


if page == pages[2] :
    st.write("###    Analyses descriptives des donn√©es")
    
    fig = plt.figure()
    top_20_banques = df_cleaned["page"].value_counts().head(20).index
    filtered_df = df_cleaned[df_cleaned['page'].isin(top_20_banques)]
    sns.countplot(y='page', data=filtered_df, order=top_20_banques)
    plt.title("Top 20 des banques par nombre d'avis")  
    st.pyplot(fig)

    fig = plt.figure()
    filtered_avis = df_cleaned[(df_cleaned['n_avis'] >= 1) & (df_cleaned['n_avis'] <= 10)]
    sns.countplot(x='n_avis', data=filtered_avis)
    plt.title("Distribution du nombre d'avis donn√©s par utilisateur (1 √† 10 avis)")
    st.pyplot(fig) 

    #fig = plt.figure()
    #sns.countplot(y='localisation',
                #data=df_cleaned,
                #order=df_cleaned['localisation'].value_counts().iloc[:10].index)  # top 10 localisations
    #plt.title('Top 10 des localisations des utilisateurs')
    #st.pyplot(fig) 
    

    fig = plt.figure()
    df_cleaned['length_avis'] = df_cleaned['text_total'].apply(len)
    sns.boxplot(x='etoiles', y='length_avis', data=df_cleaned)
    plt.title('Longueur des avis par notes')
    st.pyplot(fig)

if page == pages[3] :
    st.write("###   Mod√©lisation")
    st.write ("""
              - **Split des donn√©es en train et test avant la s√©lection √©quilibr√©e des √©toiles**:
  - Bas√© sur un tirage al√©atoire √©gal au nombre de messages dans la classe la plus minoritaire.
- **Dataset final** : 15 000 avis.
  - 30% destin√©s au jeu de test.
- **Benchmark pour √©valuer diff√©rents mod√®les** :
  - SVM
  - Random Forests
  - XGBOOST
  - KNN
  - SVC
  - Logistic Regression
  - CAMEMBERT
- **Tests pour chaque mod√®le** :
  - Features num√©riques uniquement : nombre d'avis, sentiment (score inf√©r√© par CAMEMBERT), longueur de l'avis.
  - Features num√©riques et texte de l'avis (concat√©nation du titre et de l'avis).
- **Entra√Ænement avec hyperparam√®tres par d√©faut pour chaque mod√®le, suivi d'une grille de recherche des meilleurs param√®tres (sauf CAMEMBERT)**.
""")
    st.write("Le mod√®le de deep learning d'architecture Transformer Camembert a donn√© les meilleurs r√©sultats. Sur les donn√©es de test il a atteint une pr√©cision, un recall et un f1 de 0.63 chacun. Le deuxi√®me mod√®le le plus performant a √©t√© Random Forest avec un f1 de 0.55. Ce score a √©t√© obtenu sur les features num√©riques uniquement et par une grille qui a retenu les param√®tres suivants : 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 20, 'n_estimators': 100. Le troisi√®me mod√®le le plus performant suit de pr√®s le deuxi√®me, il s‚Äôagit de XGBOOST avec un score de 0.54 obtenu sur les features num√©riques et les hyperparam√®tres par d√©faut, la recherche par grille a donn√© le m√™me score f1.")
    st.dataframe(pd.read_csv(f"{key_path}/soutenance/benchmark_modelisationI.csv", index_col=0).iloc[0:3,:])
    all_models = st.checkbox("visualiser tout le benchmark")
    if all_models:
        st.dataframe(pd.read_csv(f"{key_path}/soutenance/benchmark_modelisationI.csv", index_col=0))


    
    st.write("###   Interpr√©tation des r√©sultats")
    st.write("Le score f1 de 0.63 sur 5 classes est trois fois plus performant qu'une classification au hasard. Sans surprise c'est le mod√®le de deep learning bas√© sur l'architecture Transformers qui atteint le meilleur score. Dans l'absolu cependant ce score n'est pas optimal, id√©alement notre score aurait d√ª se situer au-dessus de 0.75. Cependant la pr√©diction d'√©toile est par nature tr√®s d√©licate, d‚Äôune part parce qu‚Äôil s'agit d'interpr√©ter des donn√©es non structur√©es (du texte) et d'autre part car l'appr√©ciation des √©toiles peut varier d'une personne √† l'autre. Par exemple certains usagers peuvent estimer, selon l'adage scolaire, qu'un score parfait (20/20 ou 5 √©toiles sur 5) n'existe pas, et vont donc donner 4 √©toiles alors que d'autres utilisateurs pour une satisfaction similaire en mettraient 5. De m√™me la diff√©rence dans le ¬´ ventre mou ¬ª, entre 2 et 3 ; 3 et 4 √©toiles peut √™tre sujette √† des variations interpersonnelles importantes. Dans l'ensemble et malgr√© un score non optimal, nous sommes satisfaits de la performance du mod√®le Camembert. Nous devons aussi noter ici que les mod√®les de machine learning utilis√©s ont √©galement b√©n√©fici√© de la puissance de Camembert puisqu'ils utilisaient un score de sentiment inf√©r√© par ce mod√®le, mais m√™me dans ces cas-l√† l'inf√©rence de Camembert sur le texte a donn√© de meilleurs r√©sultats.")
    st.write("### Focus sur le r√©sultat Random Forest")
    st.write("""
Nous utilisons aussi la technique TF-IDF pour vectoriser le texte des avis (limit√© √† 1000 caract√©ristiques pour simplifier) et pr√©parer les donn√©es pour un mod√®le de for√™t al√©atoire. Il divise les donn√©es en ensembles d'entra√Ænement et de test, entra√Æne le mod√®le sur l'ensemble d'entra√Ænement, puis pr√©dit les r√©sultats sur l'ensemble de test. Nous obtenons les r√©sultats suivants :
""")
    st.image(f"{key_path}/soutenance/crosstab_RF.png")
    st.write("""Le mod√®le semble bien performer pour les classes extr√™mes (1 et 5 √©toiles), mais il a du mal avec les classes interm√©diaires.
    La matrice de confusion normalis√©e affich√©e ci-dessus indique les performances du mod√®le Random Forest sur l'ensemble de test. Les valeurs de la matrice sont normalis√©es par le nombre d'observations r√©elles pour chaque classe, ce qui nous permet de voir la proportion des pr√©dictions correctes par rapport au total des cas pour chaque classe r√©elle.

             """)
    


if page == pages[4] :

    st.write("### Mod√©lisation II classification des sentiments (Communication, Efficacit√©, Valeur √©conomique)")
    st.write("""
- **Classification des sentiments des utilisateurs concernant** :
  - Communication
  - Efficacit√©
  - Valeur ajout√©e
  - **M√©thode** : Similarit√© s√©mantique.
- **Caract√©risation des arguments des usagers pour expliquer leur notation** :
  - Identification des aspects positifs et n√©gatifs des services.
  - Objectif : Augmenter la qualit√© des services et la satisfaction des clients.
""")
   
    tableau_labels = st.dataframe(pd.read_excel(f"{key_path}/soutenance/tableau_labels.xlsx"))
    
    st.write("""
- **Notre benchmark √©valuera plusieurs strat√©gies** :
  - **Granularit√© des √©l√©ments compar√©s** :
    - Phrases de l'avis contre phrase des exemples de r√©f√©rence
    - Phrases de l'avis vs liste enti√®re des exemples
    - Avis complet vs liste enti√®re des exemples
  - **Utilisation de l'avis** :
    - Sans filtre de mots vides
    - Avec un filtre de mots vides
    - Avec un filtre sur les phrases positives/n√©gatives
    - Sans filtre de sentiment
- **Seuil optimal de similarit√©**:
    - Tester un seuil de similarit√© entre 0.65 et .99
""")
    st.write("Un premier test sur les donn√©es d'entrainement montre de meilleures performances en utilisant l'avis sans filtre de mots vides et avec un filtre de sentiment")
    baseline_banchmark_sem= pd.read_csv(f"{key_path}/soutenance/baseline_semantic_bench.csv")
    fig_sem_bench_test = pd.read_csv(f"{key_path}/soutenance/benchmark_sem_test.csv", index_col=0)


    plt_1 = plt.figure(figsize=(12,10))
    plt.plot(baseline_banchmark_sem.threshold,baseline_banchmark_sem.Stop_words, label ="stop words", color ="indianred")
    plt.plot(baseline_banchmark_sem.threshold,baseline_banchmark_sem.Stop_words_sents, label ="stop words + sentiment", color ="indianred",linestyle="--")
    plt.plot(baseline_banchmark_sem.threshold, baseline_banchmark_sem.All_words, label = "all words", color="seagreen")
    plt.plot(baseline_banchmark_sem.threshold, baseline_banchmark_sem.All_words_sents, label ="all words + sentiment", linestyle="--", color="seagreen")
    plt.grid(True, which='both', linestyle=':', linewidth=0.5)
    plt.xlabel("similarity threshold used")
    plt.ylabel("f1 score")
    plt.legend()

    st.pyplot(plt_1)

    
    def heat(train_test):
        # pivot table heatmap
        benchmark = pd.read_csv(f"{key_path}/soutenance/benchmark_sem_{train_test}.csv")
        pivot = benchmark.pivot_table(index='code_mode', columns='test', values='f1')
        fig_sem_bench = plt.figure(figsize=(12, 16))  
        heatmap = sns.heatmap(pivot, annot=True, fmt=".2f", cmap="YlGnBu", linewidths=0, linecolor='grey')

        # horizontal lines 
        for i in range(0, len(pivot.index), 4):
            plt.axhline(i, color='white', linestyle=':', linewidth=2)

        # Label the color bar
        color_bar = heatmap.collections[0].colorbar
        color_bar.set_label('f1')

        plt.title(f'Heatmap of best {train_test} F1 Scores')
        heatmap.xaxis.tick_top() 
        plt.xticks(rotation=45, ha='left')
        return fig_sem_bench 
    
    st.write("#### R√©sultats benchmark sur donn√©es d'entrainement")
    st.write("nous avons test√© l'ensemble des strat√©gies pour les 6 labels sur les donn√©es d'entrainement:")
    st.image(f"{key_path}/soutenance/heatmap_train.png", caption='') 

    #fig_sem_bench_train = heat("train")
    #st.pyplot(fig_sem_bench_train)

    st.write("#### R√©sultats benchmark sur donn√©es de validation")
    #fig_sem_bench_val = heat("validation")
    #st.pyplot(fig_sem_bench_val)
    st.write("Puis nous avons test√© nos strat√©gies sur des donn√©es de validation, qui incluent des messages in√©dits")
    st.image(f"{key_path}/soutenance/heatmap_validation.png", caption='')

    val_best_params = pd.read_csv(f"{key_path}/soutenance/best_params_validation.csv")
    st.write('Pour la validation, la meilleure combinaison √©tait:')
    st.dataframe(val_best_params)

    st.write("#### Evaluation des r√©sultats avec les donn√©es test")
    st.write('Nous avons repris les meilleurs param√®tres puis test√© leur efficacit√© sur un dernier jeu de test:')
    st.dataframe(fig_sem_bench_test)

    st.write("""
- **Bien que l'utilisation des mots vides et le filtrage par sentiment aient √©t√© les moins efficaces lors de la phase d'entra√Ænement** :
  - Devenus des atouts pr√©cieux lors des phases de validation et de test face √† des donn√©es in√©dites.
- **Nos tests finaux montrent des r√©sultats contrast√©s** :
  - **Scores F1 √©lev√©s** :
    - bad_com : 0.80
    - bad_efficacy : 0.71
  - **Scores moyens** :
    - good_com : 0.60
    - good_efficacy : 0.60
  - **Scores bas** :
    - good_value : 0.57
    - bad_value : 0.54
  - Tous ces scores sont nettement meilleurs que le hasard (0.2), mais devraient id√©alement √™tre plus √©lev√©s.
- **Interpr√©tation des faibles scores de good_value et bad_value** :
  - Manque de coh√©rence des espaces s√©mantiques auxquels ils se rapportent.
  - Regroupement de sujets vari√©s (frais, taux d'int√©r√™t, pr√™ts) sous les √©tiquettes good_value et bad_value.
  - **Suggestion r√©trospective** : Garder des √©tiquettes s√©par√©es pour ces diff√©rents sujets aurait pu donner des scores de pr√©cision individuellement plus √©lev√©s.
""")
    st.write("###   Classification sur l'ensemble des avis")
    st.write("Nous avons effectu√© l'√©tiquetage sur l'ensemble du jeu de donn√©es (105000 avis) et nous avons veill√© √† retirer l'√©tiquetage des avis o√π deux √©tiquettes oppos√©es existaient, pour ne tenir compte que des opinions clairement tranch√©es. Sur la page suivante, vous trouverez la repr√©sentation des entreprises bancaires ayant plus de mille avis.")

if page == pages[5]:
    st.write("### Pr√©diction")
    st.write("Nous avons effectu√© l'√©tiquetage sur l'ensemble du jeu de donn√©es (environs 100 000 avis) et nous avons veill√© √† retirer l'√©tiquetage des avis o√π deux √©tiquettes oppos√©es existaient, pour ne tenir compte que des opinions clairement tranch√©es.")
    st.write("En utilisant la proximit√© s√©mantique et des r√©f√©rences issues d'une labelisation √† la main, nous pouvons pr√©dire les sentiment des avis concernant la Communication, la Valeur ajout√©e et l'Efficacit√© du service bancaire.")


    df = pd.read_csv(f"{key_path}/soutenance/df_sim_small.csv")
    references = pd.read_csv(f"{key_path}/soutenance/references_bag.csv")


    def allocate_lab(sim_score, y_pred, thresh):
        #print("thresh", thresh, "sim_score", sim_score)
        try:
            if max(sim_score) > thresh:
                y_pred.append(1)
                #print(max(sim_score), "over threshold", round(thresh,2), "y_pred = 1")
            else:
                y_pred.append(0) 
                #print(max(sim_score), "under threshold", round(thresh,2), "y_pred = 0")
        except:
            y_pred.append(0)
            #print("error, y_pred = 0")
        return y_pred

    # review sentence vs reference sentence
    def decision_sentiment(sentiment,label_of_interest, word_mode):
        # determining if using stop words or full version of reference texts
        if "stop" in word_mode:
            ref_bag = label_of_interest+"_stop"
        elif "all" in word_mode:
            ref_bag = label_of_interest
        else:
            print("error in word_mode?", word_mode)

        # determining if using sentiment filtered review sentences or all reviews sentences
        if sentiment == True:
            if "good" in label_of_interest:
                if "stop" in word_mode:
                    reviews= "text_clean_sentences_pos_stop"
                else:
                    reviews =  "text_clean_sentences_pos"
            elif "bad" in label_of_interest:
                if "stop" in word_mode:
                    reviews =  "text_clean_sentences_neg_stop"
                else:
                    reviews =  "text_clean_sentences_neg"
            else:
                print("mispelling in label_of_interest?", label_of_interest)

        elif sentiment == False:
            # for some reason the original, uncleaned punctuation versions give much better accuracy
            if "stop" in word_mode:
                reviews = "text_stop"
            else:
                reviews = "text_total"
                
        else :
            print("error: no sentiment / granularity found")

        return reviews, ref_bag

    def review_sentence_vs_ref_sentence(i,df,label_of_interest, thresh,word_mode, sentiment=True):
        test_name = "review_sentence_vs_ref_sentence"
        #print("passing",test_name) 
        reviews,ref_bag = decision_sentiment(sentiment,label_of_interest, word_mode)
        ref_bag = nlp(references[ref_bag].iloc[0])
        y_pred = [] 
        sim_score = []
        try:
            review = nlp(df[reviews].iloc[i])
            review_sentences = review.sents
            for review_sentence in review_sentences: # take each review sentence
                if len(review_sentence) > 1:
                    for sentence_exemple in ref_bag.sents:
                        if len(sentence_exemple) > 1:
                            temp_sim_score = round(sentence_exemple.similarity(review_sentence),2) # test similarity with whole reference bag
                            sim_score.append(temp_sim_score)
        except:
            #print("message null")
            sim_score.append(0.0)
        y_pred = allocate_lab(sim_score, y_pred, thresh) # if similarity failed, mark as 0 (empty review or not sentence aligned with label sentiment if sentiment = True)     
        return y_pred

    # Comparing whole review vs whole reference bag, returns y_pred series
    def review_vs_whole_ref_bag(i,df,label_of_interest, thresh,word_mode, sentiment=True):
        # establish the correct review granularity, review and reference pieces to integrate based on sentiment bool, stop_word (word_mode) bool and label of interest
        reviews,ref_bag = decision_sentiment(sentiment,label_of_interest, word_mode) 
        #print("for label", label_of_interest)
        #print("review colname", reviews)
        #print("reference bag colname", ref_bag)
        ref_bag = nlp(references[ref_bag][0]) # we convert the references once to nlp before the loop
        y_pred = []
        sim_score = []
        try:
            review = nlp(df[reviews].iloc[i])
            sim_score.append(round(ref_bag.similarity(review),2)) # compare it with the full reference bag
            allocate_lab(sim_score, y_pred, thresh) # if similarity score is > than threshold we append 1, otherwise: 0
        except: # if similarity test fails, we put 0 (in this case na or non text review)
            print("nan or error on message:", review)
            y_pred.append(0)
        return y_pred 
        
    sim = pd.DataFrame()
    def predi (i,sim=sim):
        sim['c_bad_com'] = review_sentence_vs_ref_sentence(i,df,"c_bad_com", 0.73,"stopwords", sentiment=True)
        sim['c_bad_efficacy'] = review_vs_whole_ref_bag(i,df,"c_bad_efficacy", 0.86, "allwords", sentiment=False)
        sim['c_good_efficacy'] = review_sentence_vs_ref_sentence(i,df, "c_good_efficacy", 0.71,"stopwords", sentiment=True)
        sim['c_good_com'] = review_sentence_vs_ref_sentence(i,df, "c_good_com", 0.68,"stopwords", sentiment=True)
        sim['c_good_value'] = review_sentence_vs_ref_sentence(i,df, "c_good_value", 0.68,"stopwords", sentiment=True)
        sim['c_bad_value'] = review_sentence_vs_ref_sentence(i,df, "c_bad_value", 0.69,"stopwords", sentiment=True)

        sim = sim.astype("bool")
        
        if sim['c_bad_com'][0]:
            if sim['c_good_com'][0]:
                b_com = "üòê une communication mitig√©e"
            else:
                b_com ="üëé une mauvaise communication"
        else:
            if sim['c_good_com'][0]:
                b_com = "üëç une bonne communication"
            else:
                b_com= ""#"üòê une communication mitig√©e"

        if sim['c_bad_value'][0]:
            if sim['c_good_value'][0]:
                b_value = "üòê un rendement √©conomique mitig√©"
            else:
                b_value = "üëé un mauvais rendement √©conomique"
        else:
            if sim['c_good_value'][0]:
                b_value = "üëç un bon rendement √©conomique"
            else:
                b_value = ""#"üòê un rendement √©conomique mitig√©"

        if sim['c_bad_efficacy'][0]:
            if sim['c_good_efficacy'][0]:
                b_efficacy = "üòê une efficacit√© mitig√©e"
            else:
                b_efficacy ="üëé est inefficace"
        else:
            if sim['c_good_efficacy'][0]:
                b_efficacy = "üëç est efficace"
            else:
                b_efficacy =""# "üòê a une efficacit√© mitig√©e"
        
        if sim['c_bad_com'][0] + sim['c_good_com'][0] + sim['c_bad_value'][0] + sim['c_good_value'][0] + sim['c_bad_efficacy'][0] + sim['c_good_efficacy'][0]:
            st.write(f"l'avis consid√®re que la banque {df.Soci√©t√©[i]} a:")
            st.write(b_com)
            st.write(b_value)
            st.write(b_efficacy)
        else:
            st.write("pas de sentiment particulier d√©t√©ct√©")
        b_com,b_value,b_efficacy = "","",""
   
    st.write("#### 1) Pr√©diction par avis (√©chantillon de 200 avis choisis au hasard)")
    i = st.slider(
        "## Choisir un avis:",
        1, 199, 1)
    st.write(df.text_total[i])

    if st.button("Pr√©diction"):
        predi(i,sim)

    # visu banques

    from math import pi

    df_banks = pd.read_csv(f"{key_path}/soutenance/tabs_banques.csv")
    n = len(df_banks)

    def pyramid(df, one_all, bank="all banks",ax=None):
        if bank != "all banks":
            #print(f'Focusing on bank {bank}')
            df = df[df.Soci√©t√© == bank]
        else:
            print("Matched all banks")
            df = df
        
        ratio_efficacy = round(df.abs_good_efficacy.iloc[0]/(df.abs_good_efficacy.iloc[0]+df.abs_bad_efficacy.iloc[0]),2)
        ratio_com = round(df.abs_good_com.iloc[0]/(df.abs_good_com.iloc[0]+ df.abs_bad_com.iloc[0]),2)
        ratio_value = round(df.abs_good_value.iloc[0]/(df.abs_good_value.iloc[0] + df.abs_bad_value.iloc[0]),2)
        n = df.n.iloc[0]
        # Define the number of variables and their ratings
        num_vars = 3
        ratings = [ratio_com, ratio_efficacy, ratio_value]
        ratings_sum = sum(ratings)
   
        if ratings_sum > 2:
            data_color = "ForestGreen"
        elif ratings_sum >1.5:
            data_color = "DarkOrange"
        else:
            data_color = "IndianRed"
        # Compute angle for each axis
        angles = np.linspace(0, 2 * pi, num_vars, endpoint=False).tolist()
        angles += angles[:1]  # Complete the loop

        # Rotation to level the triangle
        angles = [angle + pi / 2 for angle in angles]

        # Ratings need to be repeated at the end to close the plot
        ratings = np.concatenate((ratings, [ratings[0]]))

        # Perfect ratings for reference
        perfect_ratings = np.array([1, 1, 1, 1])

        # Check if an axis is provided
        if ax is None:
            fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))
        
        # Set the facecolor and plot
        ax.set_facecolor('white')
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(['Communication\n', '\nEfficacit√©', '\nValeur'], fontsize=18, color=data_color)
        
        # Hide circular lines and y-axis labels
        ax.set_yticklabels([])
        ax.yaxis.grid(False)

        # Set the limit for the radial axis
        ax.set_ylim(0, 1)

        # Define a small offset for labels to avoid overlap with high scores
        label_offset = 1.1  # You can adjust this value as needed

        ax.plot(angles, perfect_ratings, linewidth=1, linestyle=':', color='grey', alpha=0.5)
        ax.fill(angles, perfect_ratings, color='Ivory', alpha=0.5)
        # plotting the perfect triangle for visual reference
        ax.plot(angles, ratings, linewidth=2, linestyle='solid', color=data_color)
        ax.fill(angles, ratings, data_color, alpha=0.25)
        ax.spines['polar'].set_visible(False)
        ax.grid(color='grey', linestyle='--', linewidth=0.5, alpha=0.5)
        plt.yticks([], [], color="black", size=8)
        plt.ylim(0, 1)

        # Adding values at triangle tips
        for angle, rating in zip(angles[:-1], ratings[:-1]):
            ax.text(angle, rating + 0.10, f'{rating:.2f}', ha='center', va='center', fontsize=16, color=data_color)
        
        # Adding the sum of ratings in bold at the center of the triangle
        ax.text(0, 0, f'{ratings_sum:.2f}', ha='center', va='center', fontsize=25, color= data_color, fontweight='bold')
        ax.set_title(f"Scores pour {bank} (n={n} avis)", size=25)
        if one_all =="one":
            return fig,ax

    st.write ("#### 2) Scores globaux pour les banques")
    banque = st.selectbox("",df_banks.Soci√©t√©,index = None,
                          placeholder="choisissez une banque")
    if banque:
        figue, axe = pyramid(df_banks, "one",banque )
        st.pyplot(figue)

    all_banques_check = st.checkbox("Visualiser toutes les banques")
    if all_banques_check:
        # plotting the pyramids
        cols = 3  
        rows = n // cols + (n % cols > 0)  
        fig, axs = plt.subplots(rows, cols, figsize=(6 * cols, 6 * rows), subplot_kw=dict(polar=True))
        axs = axs.flatten()  

        fig.suptitle("Ratios de sentiment utilisateur positif concernant la communication, l'efficacit√© et la valeur des services bancaires pour les banques ayant plus de 1000 avis", fontsize=20)  # Add an overall title

        for idx, bank in enumerate(df_banks.Soci√©t√©):
            ax = axs[idx]
            pyramid(df_banks, "all", bank, ax)
            ax.grid(False)  
            ax.set_yticklabels([]) 
            ax.set_title(f'{bank}', fontsize=20) 

        for ax in axs[len(df_banks):]:
            ax.set_visible(False)

        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) 

        plt.show()
        st.pyplot(fig)

    st.write("""
- **Cette lab√©lisation permet de tester les facteurs √©conomiques** :
  - Analyse de sentiment associ√©e aux avis √©mis sur la **valeur √©conomique**.
  - Association de ces sentiments √† des notions financi√®res telles que :
    - Compte
    - Solde
    - Cr√©dit
    - D√©bit
    - Pr√™t
    - Hypoth√®que
    - Int√©r√™t
    - Investissement
    - √âpargne
    - Transaction
    - D√©p√¥t
    - Retrait
    - Frais
    - Charge
    - Budget
    - Finance
    - Argent
    - Monnaie
    - √âchange
    - Taux
    - Action
    - Obligation
    - March√©
    - √âconomique
    - √âconomie
    - Financier
    - Fiscal
    - Inflation
    - D√©flation
    - Taxe
    - Revenu
    - Profit
    - Perte
    - √âvaluation
    - Actif
    - Passif
    - √âquit√©
    - Dividende
    - Portefeuille
- **Observations** :
  - Polarisation des opinions n√©gatives non pas sur les services habituels li√©s aux √©changes ou des pr√™ts.
  - Avis positifs en net pour les √©changes d'informations et les pr√™ts.
  - Opinions n√©gatives concentr√©es sur la notion de "perte" ou de compte.
  - Sugg√®re qu‚Äôun facteur conjoncturel serait √† l‚Äô≈ìuvre.
""")    
    st.image(f"{key_path}/references/Net sentiment.jpg", caption='')  
    st.write("Pour v√©rifier cela, nous d√©taillons la fr√©quence des opinions exprim√©es en fonction des mois durant lesquels ces derni√®res sont exprim√©es. Nous constatons une hausse brutale de ces opinions √† la fin de notre √©chantillon aux alentours de Octobre 2023. Les entreprises fran√ßaises ont effectivement commenc√© √† rencontrer de plus grandes difficult√©s vers la fin de l'ann√©e 2023.")
    st.image(f"{key_path}/references/timeserie.png", caption='')    
    st.write("Les d√©faillances d'entreprises ont augment√© significativement, refl√©tant une situation √©conomique tendue marqu√©e par l'inflation, la hausse des taux d'int√©r√™t et le ralentissement √©conomique. Ces facteurs ont combin√© leurs effets avec le d√©but du remboursement des dettes accumul√©es pendant la crise du Covid-19, comme les Pr√™ts Garantis par l'√âtat (PGE), exacerbant les difficult√©s pour de nombreuses entreprises. Ces donn√©es montrent clairement que la fin de l'ann√©e 2023 a marqu√© un tournant pour les entreprises fran√ßaises, avec une augmentation significative des faillites et des proc√©dures collectives, signalant des d√©fis accrus en mati√®re de liquidit√© et de solvabilit√© pour les entreprises de toutes tailles, et notamment pour les plus petites d‚Äôentre elles ou les auto-entrepreneurs. ")

    st.write("### Perspectives")
    st.write("""des travaux futurs pourraient:
  - Utiliser une labelisation plus √©tendue, notamment sur les aspects economiques
  - Utiliser des mod√®les de generative AI pour:
    - Lab√©liser les messages
    - Produire des r√©sum√©s des principaux pain points              
             """)