import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from os import listdir
#python -m spacy download fr_core_news_lg
import spacy
#pip install time
#pip install warnings
import time
import warnings

liste=pd.read_csv("../data/liste_entreprises_banque.csv")
df = pd.read_csv("../data/avis/general_df.csv")
df_cleaned = pd.read_csv("../data/avis/df_cleaned.csv")

st.title("Projet d'analse des avis et verbatim")
st.sidebar.title("Sommaire")
pages=["I.	Introduction et objectif du projet", "II.	Pr√©parations des donn√©es ", "III.	Analyses descriptives des donn√©es", "IV.	Mod√©lisations", "V.	Pr√©diction"]
page=st.sidebar.radio("Aller vers", pages)


if page == pages[0] : 
    st.write("### Introduction et objectif")
    st.write("Faire des mod√©lisations √† partir des avis et verbatim √† partir du site 'fr.trustpilot.com/categories/bank' afin d'analyser les verbatim et le lien entre les notations et les verbatim")
    st.write("- Pr√©dire la satisfaction d'un client : probl√®me de r√©gression et Entra√Ænement supervis√© possible.")
    st.write("- Identifier les points cl√©s des avis : localisation, nom d'entreprise... ")
    st.write("- Extraire les propos du commentaire et trouver les mots importants : probl√®me de livraison, article d√©fectueux... avec l'approche non supervis√©e avec CamemBert")
    st.write("- Trouver une r√©ponse rapide adapt√©e pour r√©pondre au commentaire, par exemple sur les reviews Google")

    st.write("### Aper√ßu de la base de donn√©es t√©l√©charg√©e")

    st.dataframe(liste.head())
    st.dataframe(df.head())
    st.write(df.shape)
    st.dataframe(df.describe())

    if st.checkbox("Afficher les NA") :
        st.dataframe(df.isna().sum())



if page == pages[1] : 
    st.write("### Pr√©parations des donn√©es")
    st.write("Nous avons retir√© du dataset les avis li√©s √† l'une des banques qui semblait √©maner de bots. Cette soci√©t√© a environs 60 000 avis avec la grande majorit√© de 5 √©toiles. Nous avons fait le split des donn√©es train et test avant de faire une s√©lection √©quilibr√©e des √©toiles (pour √©viter un leaking de la structure des r√©sultats attendus en test dans l'entrainement) en se basant sur un tirage al√©atoire √©gal au nombre de messages pr√©sents dans la classe la plus minoritaire. Le dataset retenu faisait 15 000 avis, dont 30% du jeu destin√© au jeu de test. Nous avons fait un benchmark pour √©valuer la performance de diff√©rents mod√®les : SVM, Random Forests, XGBOOST, KNN, SVC, Logistic Regression et CAMEMBERT.")
    st.write("Pour chaque mod√®le, nous avons test√© les features num√©riques uniquement d'une part : le nombre d'avis, le sentiment (score inf√©r√© par CAMEMEMBERT) et la longueur de l'avis, et d'autre part les features num√©riques et le texte de l'avis (concat√©nation du titre et de l'avis). ")
    st.write("Pour chaque mod√®le (except√© CAMEMBERT) nous avons lanc√© un entrainement avec les hyper param√®tres par d√©faut puis lanc√© une grille de recherche des meilleurs param√®tres.")

    st.write("### Aper√ßu de la base de donn√©es nettoy√©es")

    st.dataframe(df_cleaned.head())


if page == pages[2] :
    st.write("###    Analyses descriptives des donn√©es")
    
    fig = plt.figure()
    top_20_banques = df_cleaned["Soci√©t√©"].value_counts().head(20).index
    filtered_df = df_cleaned[df_cleaned['Soci√©t√©'].isin(top_20_banques)]
    sns.countplot(y='Soci√©t√©', data=filtered_df, order=top_20_banques)
    plt.title("Top 20 des banques par nombre d'avis")  
    st.pyplot(fig)

    fig = plt.figure()
    filtered_avis = df_cleaned[(df_cleaned['n_avis'] >= 1) & (df_cleaned['n_avis'] <= 10)]
    sns.countplot(x='n_avis', data=filtered_avis)
    plt.title("Distribution du nombre d'avis donn√©s par utilisateur (1 √† 10 avis)")
    st.pyplot(fig) 

    fig = plt.figure()
    sns.countplot(y='localisation', data=df_cleaned, order=df_cleaned['localisation'].value_counts().iloc[:10].index)  # top 10 localisations
    plt.title('Top 10 des localisations des utilisateurs')
    st.pyplot(fig) 

    fig = plt.figure()
    df_cleaned['length_avis'] = df_cleaned['text_total'].apply(len)
    sns.boxplot(x='etoiles', y='length_avis', data=df_cleaned)
    plt.title('Longueur des avis par notes')
    st.pyplot(fig)

if page == pages[3] :
    st.write("###   Mod√©lisation")
    st.write("Pour chaque mod√®le, nous avons test√© les features num√©riques uniquement d'une part : le nombre d'avis, le sentiment (score inf√©r√© par CAMEMEMBERT) et la longueur de l'avis, et d'autre part les features num√©riques et le texte de l'avis (concat√©nation du titre et de l'avis).")
    st.write("Le mod√®le de deep learning Camembert a donn√© les meilleurs r√©sultats. Sur les donn√©es d'entrainement il a atteint une pr√©cision, un recall et un f1 de 0.63 chacun. Le deuxi√®me mod√®le le plus performant a √©t√© Random Forest avec un f1 de 0.55. Ce score a √©t√© obtenu sur les features num√©riques uniquement et par une grille qui a retenu les param√®tres suivants : 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 20, 'n_estimators': 100. Le troisi√®me mod√®le le plus performant suit de pr√®s le deuxi√®me, il s‚Äôagit de XGBOOST avec un score de 0.54 obtenu sur les features num√©riques et les hyperparam√®tres par d√©faut, la recherche par grille a donn√© le m√™me score f1.")
    bench_list = listdir("../reports/benchmark")
    # bench_list.remove(".DS_Store")

    benchmark = pd.DataFrame()

    for file in bench_list:
        df = pd.read_csv(f'../reports/benchmark/{file}', index_col=0)
        benchmark = pd.concat([benchmark, df])

    new_cols = ['model', 'grid search', 'score', 'precision', 'recall', 'f1', 'time_taken_mns', 'run_date', 'used/best params']
    benchmark = benchmark.reindex(columns=new_cols)
    benchmark = benchmark.sort_values("f1", ascending = False)
    benchmark= benchmark[benchmark.score!='na']
    benchmark

    st.write("###   Interpr√©tation des r√©sultats")
    st.write("Le score f1 de 0.63 sur 5 classes est trois fois plus performant qu'une classification au hasard. Sans surprise c'est le mod√®le de deep learning bas√© sur l'architecture Transformers qui atteint le meilleur score. Dans l'absolu cependant ce score n'est pas optimal, id√©alement notre score aurait d√ª se situer au-dessus de 0.75. Cependant la pr√©diction d'√©toile est par nature tr√®s d√©licate, d‚Äôune part parce qu‚Äôil s'agit d'interpr√©ter des donn√©es non structur√©es (du texte) et d'autre part car l'appr√©ciation des √©toiles peut varier d'une personne √† l'autre. Par exemple certains usagers peuvent estimer, selon l'adage scolaire, qu'un score parfait (20/20 ou 5 √©toiles sur 5) n'existe pas, et vont donc donner 4 √©toiles alors que d'autres utilisateurs pour une satisfaction similaire en mettraient 5. De m√™me la diff√©rence dans le ¬´ ventre mou ¬ª, entre 2 et 3 ; 3 et 4 √©toiles peut √™tre sujette √† des variations interpersonnelles importantes. Dans l'ensemble et malgr√© un score non optimal, nous sommes satisfaits de la performance du mod√®le Camembert. Nous devons aussi noter ici que les mod√®les de machine learning utilis√©s ont √©galement b√©n√©fici√© de la puissance de Camembert puisqu'ils utilisaient un score de sentiment inf√©r√© par ce mod√®le, mais m√™me dans ces cas-l√† l'inf√©rence de Camembert sur le texte a donn√© de meilleurs r√©sultats.")
    st.write("###   Labelisation")
    st.write("Nous avons fait une classification des sentiments des utilisateurs concernant la communication, l'efficacit√© et la valeur ajout√©e par similarit√© s√©mantique. Par la suite nous avons entrepris de caract√©riser les arguments que les usagers invoquent pour expliquer leur notation, afin de d√©gager les aspects positifs et n√©gatifs des services, qui pourraient √™tre utiles pour augmenter leur qualit√© et la satisfaction des clients.")
    df = pd.read_excel("../data/labelisation.xlsx", header=0, index_col=0)
    st.dataframe(df.head(7))

    st.write("###   R√©sultat des diff√©rents traitements")
    st.write()

    bench= pd.read_csv("../reports/similarity/best_validation_params.csv", index_col=0)
    st.dataframe(bench.head(7))    



if page == pages[4]:
    st.write("### Pr√©diction")
    st.write("En utilisant la proximit√© s√©mantique et des r√©f√©rences issues d'une labelisation √† la main, nous pouvons pr√©dire les sentiment des avis concernant la Communication, la Valeur ajout√©e et l'Efficacit√© du service bancaire.")


    df = pd.read_csv("../data/df_sim_small.csv")
    references = pd.read_csv('../data/references_bag.csv')

    nlp = spacy.load("fr_core_news_lg")

    def allocate_lab(sim_score, y_pred, thresh):
        #print("thresh", thresh, "sim_score", sim_score)
        try:
            if max(sim_score) > thresh:
                y_pred.append(1)
                #print(max(sim_score), "over threshold", round(thresh,2), "y_pred = 1")
            else:
                y_pred.append(0) 
                #print(max(sim_score), "under threshold", round(thresh,2), "y_pred = 0")
        except:
            y_pred.append(0)
            #print("error, y_pred = 0")
        return y_pred

    # review sentence vs reference sentence
    def decision_sentiment(sentiment,label_of_interest, word_mode):
        # determining if using stop words or full version of reference texts
        if "stop" in word_mode:
            ref_bag = label_of_interest+"_stop"
        elif "all" in word_mode:
            ref_bag = label_of_interest
        else:
            print("error in word_mode?", word_mode)

        # determining if using sentiment filtered review sentences or all reviews sentences
        if sentiment == True:
            if "good" in label_of_interest:
                if "stop" in word_mode:
                    reviews= "text_clean_sentences_pos_stop"
                else:
                    reviews =  "text_clean_sentences_pos"
            elif "bad" in label_of_interest:
                if "stop" in word_mode:
                    reviews =  "text_clean_sentences_neg_stop"
                else:
                    reviews =  "text_clean_sentences_neg"
            else:
                print("mispelling in label_of_interest?", label_of_interest)

        elif sentiment == False:
            # for some reason the original, uncleaned punctuation versions give much better accuracy
            if "stop" in word_mode:
                reviews = "text_stop"
            else:
                reviews = "text_total"
                
        else :
            print("error: no sentiment / granularity found")

        return reviews, ref_bag

    def review_sentence_vs_ref_sentence(i,df,label_of_interest, thresh,word_mode, sentiment=True):
        test_name = "review_sentence_vs_ref_sentence"
        #print("passing",test_name) 
        reviews,ref_bag = decision_sentiment(sentiment,label_of_interest, word_mode)
        ref_bag = nlp(references[ref_bag].iloc[0])
        y_pred = [] 
        sim_score = []
        try:
            review = nlp(df[reviews].iloc[i])
            review_sentences = review.sents
            for review_sentence in review_sentences: # take each review sentence
                if len(review_sentence) > 1:
                    for sentence_exemple in ref_bag.sents:
                        if len(sentence_exemple) > 1:
                            temp_sim_score = round(sentence_exemple.similarity(review_sentence),2) # test similarity with whole reference bag
                            sim_score.append(temp_sim_score)
        except:
            #print("message null")
            sim_score.append(0.0)
        y_pred = allocate_lab(sim_score, y_pred, thresh) # if similarity failed, mark as 0 (empty review or not sentence aligned with label sentiment if sentiment = True)     
        return y_pred

    # Comparing whole review vs whole reference bag, returns y_pred series
    def review_vs_whole_ref_bag(i,df,label_of_interest, thresh,word_mode, sentiment=True):
        # establish the correct review granularity, review and reference pieces to integrate based on sentiment bool, stop_word (word_mode) bool and label of interest
        reviews,ref_bag = decision_sentiment(sentiment,label_of_interest, word_mode) 
        #print("for label", label_of_interest)
        #print("review colname", reviews)
        #print("reference bag colname", ref_bag)
        ref_bag = nlp(references[ref_bag][0]) # we convert the references once to nlp before the loop
        y_pred = []
        sim_score = []
        try:
            review = nlp(df[reviews].iloc[i])
            sim_score.append(round(ref_bag.similarity(review),2)) # compare it with the full reference bag
            allocate_lab(sim_score, y_pred, thresh) # if similarity score is > than threshold we append 1, otherwise: 0
        except: # if similarity test fails, we put 0 (in this case na or non text review)
            print("nan or error on message:", review)
            y_pred.append(0)
        return y_pred 
        
    sim = pd.DataFrame()
    def predi (i,sim=sim):
        sim['c_bad_com'] = review_sentence_vs_ref_sentence(i,df,"c_bad_com", 0.73,"stopwords", sentiment=True)
        sim['c_bad_efficacy'] = review_vs_whole_ref_bag(i,df,"c_bad_efficacy", 0.86, "allwords", sentiment=False)
        sim['c_good_efficacy'] = review_sentence_vs_ref_sentence(i,df, "c_good_efficacy", 0.71,"stopwords", sentiment=True)
        sim['c_good_com'] = review_sentence_vs_ref_sentence(i,df, "c_good_com", 0.68,"stopwords", sentiment=True)
        sim['c_good_value'] = review_sentence_vs_ref_sentence(i,df, "c_good_value", 0.68,"stopwords", sentiment=True)
        sim['c_bad_value'] = review_sentence_vs_ref_sentence(i,df, "c_bad_value", 0.69,"stopwords", sentiment=True)

        sim = sim.astype("bool")
        
        if sim['c_bad_com'][0]:
            if sim['c_good_com'][0]:
                b_com = "üòê une communication mitig√©e"
            else:
                b_com ="üëé une mauvaise communication"
        else:
            if sim['c_good_com'][0]:
                b_com = "üëç une bonne communication"
            else:
                b_com= ""#"üòê une communication mitig√©e"

        if sim['c_bad_value'][0]:
            if sim['c_good_value'][0]:
                b_value = "üòê un rendement √©conomique mitig√©"
            else:
                b_value = "üëé un mauvais rendement √©conomique"
        else:
            if sim['c_good_value'][0]:
                b_value = "üëç un bon rendement √©conomique"
            else:
                b_value = ""#"üòê un rendement √©conomique mitig√©"

        if sim['c_bad_efficacy'][0]:
            if sim['c_good_efficacy'][0]:
                b_efficacy = "üòê une efficacit√© mitig√©e"
            else:
                b_efficacy ="üëé est inefficace"
        else:
            if sim['c_good_efficacy'][0]:
                b_efficacy = "üëç est efficace"
            else:
                b_efficacy =""# "üòê a une efficacit√© mitig√©e"
        
        if sim['c_bad_com'][0] + sim['c_good_com'][0] + sim['c_bad_value'][0] + sim['c_good_value'][0] + sim['c_bad_efficacy'][0] + sim['c_good_efficacy'][0]:
            st.write(f"l'avis consid√®re que la banque {df.Soci√©t√©[i]} a {b_com} {b_value} {b_efficacy}")
        else:
            st.write("pas de sentiment particulier d√©t√©ct√©")
        b_com,b_value,b_efficacy = "","",""
   
    st.write("#### 1) Pr√©diction par avis")
    i = st.slider(
        "## Choisir un avis:",
        1, 199, 1)
    st.write(df.text_total[i])

    if st.button("Pr√©diction"):
        predi(i,sim)

    # visu banques

    from math import pi

    df_banks = pd.read_csv("../data/tabs_banques.csv")
    n = len(df_banks)

    def pyramid(df, one_all, bank="all banks",ax=None):
        if bank != "all banks":
            #print(f'Focusing on bank {bank}')
            df = df[df.Soci√©t√© == bank]
        else:
            print("Matched all banks")
            df = df
        
        ratio_efficacy = round(df.abs_good_efficacy.iloc[0]/(df.abs_good_efficacy.iloc[0]+df.abs_bad_efficacy.iloc[0]),2)
        ratio_com = round(df.abs_good_com.iloc[0]/(df.abs_good_com.iloc[0]+ df.abs_bad_com.iloc[0]),2)
        ratio_value = round(df.abs_good_value.iloc[0]/(df.abs_good_value.iloc[0] + df.abs_bad_value.iloc[0]),2)
        n = df.n.iloc[0]
        # Define the number of variables and their ratings
        num_vars = 3
        ratings = [ratio_com, ratio_efficacy, ratio_value]
        ratings_sum = sum(ratings)
   
        if ratings_sum > 2:
            data_color = "ForestGreen"
        elif ratings_sum >1.5:
            data_color = "DarkOrange"
        else:
            data_color = "IndianRed"
        # Compute angle for each axis
        angles = np.linspace(0, 2 * pi, num_vars, endpoint=False).tolist()
        angles += angles[:1]  # Complete the loop

        # Rotation to level the triangle
        angles = [angle + pi / 2 for angle in angles]

        # Ratings need to be repeated at the end to close the plot
        ratings = np.concatenate((ratings, [ratings[0]]))

        # Perfect ratings for reference
        perfect_ratings = np.array([1, 1, 1, 1])

        # Check if an axis is provided
        if ax is None:
            fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
        
        # Set the facecolor and plot
        ax.set_facecolor('white')
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(['Communication\n', '\nEfficacit√©', '\nValeur'], fontsize=18, color=data_color)
        
        # Hide circular lines and y-axis labels
        ax.set_yticklabels([])
        ax.yaxis.grid(False)

        # Set the limit for the radial axis
        ax.set_ylim(0, 1)

        # Define a small offset for labels to avoid overlap with high scores
        label_offset = 1.1  # You can adjust this value as needed

        ax.plot(angles, perfect_ratings, linewidth=1, linestyle=':', color='grey', alpha=0.5)
        ax.fill(angles, perfect_ratings, color='Ivory', alpha=0.5)
        # plotting the perfect triangle for visual reference
        ax.plot(angles, ratings, linewidth=2, linestyle='solid', color=data_color)
        ax.fill(angles, ratings, data_color, alpha=0.25)
        ax.spines['polar'].set_visible(False)
        ax.grid(color='grey', linestyle='--', linewidth=0.5, alpha=0.5)
        plt.yticks([], [], color="black", size=8)
        plt.ylim(0, 1)

        # Adding values at triangle tips
        for angle, rating in zip(angles[:-1], ratings[:-1]):
            ax.text(angle, rating + 0.10, f'{rating:.2f}', ha='center', va='center', fontsize=16, color=data_color)
        
        # Adding the sum of ratings in bold at the center of the triangle
        ax.text(0, 0, f'{ratings_sum:.2f}', ha='center', va='center', fontsize=25, color= data_color, fontweight='bold')
        ax.set_title(f"Scores pour {bank} (n={n} avis)", size=25)
        if one_all =="one":
            return fig,ax

    st.write ("#### 2) Scores globaux pour les banques")
    banque = st.selectbox("",df_banks.Soci√©t√©,index = None,
                          placeholder="choisissez une banque")
    if banque:
        figue, axe = pyramid(df_banks, "one",banque )
        st.pyplot(figue)

    all_banques_check = st.checkbox("Visualiser toutes les banques")
    if all_banques_check:
        # plotting the pyramids
        cols = 3  
        rows = n // cols + (n % cols > 0)  
        fig, axs = plt.subplots(rows, cols, figsize=(6 * cols, 6 * rows), subplot_kw=dict(polar=True))
        axs = axs.flatten()  

        fig.suptitle("Ratios de sentiment utilisateur positif concernant la communication, l'efficacit√© et la valeur des services bancaires pour les banques ayant plus de 1000 avis", fontsize=20)  # Add an overall title

        for idx, bank in enumerate(df_banks.Soci√©t√©):
            ax = axs[idx]
            pyramid(df_banks, "all", bank, ax)
            ax.grid(False)  
            ax.set_yticklabels([]) 
            ax.set_title(f'{bank}', fontsize=20) 

        for ax in axs[len(df_banks):]:
            ax.set_visible(False)

        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) 

        plt.show()
        st.pyplot(fig)




    